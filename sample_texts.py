
URL_1 = 'https://www.nbclosangeles.com/news/local/privacy-expert-suggests-doing-this-to-help-protect-your-personal-information-online/2749633/'
HTML_1 = 'sample_webpages/sample_001.html'
TEXT_1 = """'Popular apps and websites, such as Facebook and Amazon, that many of us use all the time, are gathering a lot of information about us, and even sharing it with others.\n\nSo the NBC4 I-Team talked to a privacy expert about the settings you might want to have in place to keep your personal information as private as possible.\n\nOur redesigned local news and weather app is live! Download it for iOS or Android — and sign up for alerts.\n\nFacebook, Amazon, Venmo and Google. Those are the apps and websites that most of us are using, and those are the ones gobbling up our data.\n\n“In most cases you’re just making all of your information public in one way or another,” said online privacy expert Hayley Kaplan. “You’re making it so easy for people to know so much about you.”\n\nBut Kaplan says a quick privacy checkup will help protect some of your personal information.\n\nLet’s start with Amazon. If you have a wish list, Kaplan says it defaults to a public setting, meaning anybody can see what’s on it. The quick fix: set it to private.\n\nNow, your browsing and purchase history aren’t public. But if you share your account with your family, they can see it all.\n\n“Let’s just say you’re sharing the account and you’ve ordered something you don’t want someone in your family to know, let’s say a birthday gift you want to keep a surprise for them. There is a way to hide that,” said Kaplan.\n\nHere are tips for keeping your Amazon account private.\n\nFor Venmo users, the default setting is public, meaning people can see everyone you’re paying and when. If you want to keep those payments to your therapist private, then you need to adjust your settings. Kaplan says you’ll also want to hide your past transactions and your contacts.\n\nHere are tips for adjusting your Venmo privacy settings.\n\nAnd if you’re not sure which cash app to use, Kaplan prefers Zelle.\n\n“It’s highly encrypted, there’s no sharing, there’s no ‘friends list’ within the app,” said Kaplan. “To me it just feels much more secure than Venmo.”\n\nAs for Facebook, you may have noticed that ads pop up based on what you’re searching for online. You can stop the social media giant from targeting ads at you by tweaking your settings.\n\nAnother settings tweak that Kaplan suggests: don’t let people tag you in posts or pictures without your approval.\n\nAnd whatever changes you make to your Facebook settings, be sure to check them often.\n\n“I can write an article that goes step by step through Facebook settings, and three days from now, 10 days from now, a year from now, it could be very different,” said Kaplan.\n\nHere’s where you can manage your Facebook privacy. And you can also do a Facebook privacy checkup.\n\nOver on Google, they just might know the most about you. Kaplan suggests you don’t allow the tech giant to track your browsing history. Here’s how to access and change your Google privacy settings.\n\nKaplan can also walk you through how to blur your home on Google maps.\n\nFinally, some sites allow you to log in using your Google or Facebook account, but Kaplan says don’t do it, because that just gives the companies even more information about you.\n\n“Education is the best ammunition you can have,” said Kaplan. “Once you’ve decided that you care about privacy and start educating yourself, you can achieve a pretty decent level for yourself.”'"""


URL_2 = 'https://www.protocol.com/vr-harassment-metaverse-bosworth'
HTML_2 = 'sample_webpages/sample_002.html'
TEXT_2 = """'How do you keep people safe in the metaverse? That\'s a question Meta, the company formerly known as Facebook, has been grappling with for some time. And the answer isn\'t all that simple.\n\nThe metaverse may be little more than a concept for now, but the safety problem is anything but theoretical: People regularly experience harassment in VR apps and experiences, including those running on Meta\'s Quest VR headset. Even the company\'s own employees are not immune. Earlier this year, an unnamed employee told co-workers in the company\'s internal Workplace forums that they had been accosted in Rec Room, with other players shouting the N-word at them without an obvious way to identify or stop the harasser. "Spoiler alert: I did not have a good time," the employee summarized.\n\nThe discussion, which became part of the public record when it was included in leaked Facebook documents supplied to Congress, shows that the problem is not isolated. One participant noted that similar cases are being brought up internally every few weeks, while another personally experienced harassment as well. "Multiple games have similar issues," one participant noted in the exchange.\n\nMeta\'s head of consumer hardware and incoming CTO, Andrew Bosworth, told Protocol on Friday that the specific incident discussed in the leaked document could have been mitigated if the employee had made use of existing reporting tools. "The tenor of the post [is] overstated and misinformed," Bosworth said. However, he also acknowledged that the problem of harassment in VR is real. He laid out ways the company is aiming to solve it, while pointing to trade-offs between making VR spaces safe and not policing people\'s private conversations. "We have [to strike] a pretty tough balance between privacy and integrity," Bosworth said.\n\nThis interview has been edited and condensed for clarity.\n\nAre your current reporting options enough to fight harassment in VR?\n\nI think the tools that we have in place are a good start. Blocking in virtual spaces is a very powerful tool, much more powerful than it is in asynchronous spaces. We can have someone not appear to exist to you. In addition, we can do reporting. This is a little bit similar to how you think of reporting in WhatsApp. Locally, on your device, totally private and secure, [you] have a little rolling buffer of what\'s the activity that happened. And you can say, "I want to report it," [and] send it to the platform developer or to us.\n\nThat kind of continuous recording is something you are only testing in Horizon so far, right?\n\nIt\'s a first-party tool that we built. It\'s the kind of thing that we encourage developers to adopt, or even make it easier for them to adopt over time. And we feel good about what that represents from a standpoint of a privacy integrity trade-off, because it\'s keeping the incidents private until somebody chooses of their own volition to say, "This is a situation that I want to raise visibility to."\n\nBut it\'s also just recording audio. How much does that have to do with the technical limitations of the Quest?\n\nIt\'s audio plus some metadata right now, [including which] users were in the area, for example. I don\'t think there is a technical limitation that prevents us from doing more. We\'re just trying to strike a trade-off between the privacy and the integrity challenges. That\'s going to be an area [where] we tread lightly, make sure [tools we roll out are] really well understood before we expand them.\n\nYou\'ve been saying that you want to put privacy first when building new products for Meta. How does that conflict with building safe products?\n\nSafety and privacy are highly related concepts and are both very high on our list of priorities. But, you know, even my friends say mean things to me sometimes. The path to infinite privacy is no product. The path to infinite safety is no social interaction. I don\'t think anyone\'s proposing we take these to their extremes.\n\nThe question is: What are healthy balances that give consumers control? And when you have privacy and safety trade-offs, that\'s super tough. The more [social VR spaces] are policed, the less privacy you\'re fundamentally able to ensure that people have. So it\'s case by case. There\'s not a one-size-fits-all solution on how to resolve those priorities when they compete.\n\nYou are also dealing with a space that\'s still very new, with a lot of VR games coming from relatively small companies. How can you help those developers fight harassment?\n\nWe want to build tools that developers can use, at the very least on our platforms. Identity is a strong example. If developers integrate our identity systems, even behind the scenes, they have a stronger ability to inherit things like blocks that suggest that two people don\'t want to be exposed to one another. There are tools that we can build — APIs, SDKs — that developers will be able to integrate. That\'s going to take time for us to build, but that\'s the direction we want to go in. Some of them we could potentially require for our own platform, some we would offer for those who choose to use [them].\n\nAs we move toward a metaverse world, what role will platform providers play in enforcing those rules? Right now, there seem to be two blueprints: game consoles, where companies have very strict safety requirements, and mobile platforms, where a company like Apple doesn\'t tell app developers how to do moderation. What will this look like for AR and VR devices in the future?\n\nOur vision for the metaverse is very interoperable. We very much expect a large number of the social spaces that people occupy in the metaverse to be cross-platform. To have people in them who are on mobile devices, in VR headsets, on PCs or laptops and on consoles and more. So this is kind of my point: You have to give a lot of the responsibility to the person hosting the social space. Are they informing customers of what the policies are and what the risks are? And if they\'re informed, are consumers allowed to make that decision for themselves?\n\nI don\'t want to be in a position where we\'re asserting control over what consumers are allowed to do in third-party applications, and what they\'re allowed to engage with.\n\nHow much does Meta\'s plan of getting a billion people to use the metaverse within the next decade depend on getting safety right from the get-go?\n\nI think it\'s hugely important. If the mainstream consumer puts a headset on for the first time and ends up having a really bad experience, that\'s obviously deleterious to our goals of growing the entire ecosystem. I don\'t think this is the kind of thing that can wait.\n\n\n\n'"""

