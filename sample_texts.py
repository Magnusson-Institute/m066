
URL_1 = 'https://www.nbclosangeles.com/news/local/privacy-expert-suggests-doing-this-to-help-protect-your-personal-information-online/2749633/'
HTML_1 = 'sample_webpages/sample_001.html'
TEXT_1 = """'Popular apps and websites, such as Facebook and Amazon, that many of us use all the time, are gathering a lot of information about us, and even sharing it with others.\n\nSo the NBC4 I-Team talked to a privacy expert about the settings you might want to have in place to keep your personal information as private as possible.\n\nOur redesigned local news and weather app is live! Download it for iOS or Android — and sign up for alerts.\n\nFacebook, Amazon, Venmo and Google. Those are the apps and websites that most of us are using, and those are the ones gobbling up our data.\n\n“In most cases you’re just making all of your information public in one way or another,” said online privacy expert Hayley Kaplan. “You’re making it so easy for people to know so much about you.”\n\nBut Kaplan says a quick privacy checkup will help protect some of your personal information.\n\nLet’s start with Amazon. If you have a wish list, Kaplan says it defaults to a public setting, meaning anybody can see what’s on it. The quick fix: set it to private.\n\nNow, your browsing and purchase history aren’t public. But if you share your account with your family, they can see it all.\n\n“Let’s just say you’re sharing the account and you’ve ordered something you don’t want someone in your family to know, let’s say a birthday gift you want to keep a surprise for them. There is a way to hide that,” said Kaplan.\n\nHere are tips for keeping your Amazon account private.\n\nFor Venmo users, the default setting is public, meaning people can see everyone you’re paying and when. If you want to keep those payments to your therapist private, then you need to adjust your settings. Kaplan says you’ll also want to hide your past transactions and your contacts.\n\nHere are tips for adjusting your Venmo privacy settings.\n\nAnd if you’re not sure which cash app to use, Kaplan prefers Zelle.\n\n“It’s highly encrypted, there’s no sharing, there’s no ‘friends list’ within the app,” said Kaplan. “To me it just feels much more secure than Venmo.”\n\nAs for Facebook, you may have noticed that ads pop up based on what you’re searching for online. You can stop the social media giant from targeting ads at you by tweaking your settings.\n\nAnother settings tweak that Kaplan suggests: don’t let people tag you in posts or pictures without your approval.\n\nAnd whatever changes you make to your Facebook settings, be sure to check them often.\n\n“I can write an article that goes step by step through Facebook settings, and three days from now, 10 days from now, a year from now, it could be very different,” said Kaplan.\n\nHere’s where you can manage your Facebook privacy. And you can also do a Facebook privacy checkup.\n\nOver on Google, they just might know the most about you. Kaplan suggests you don’t allow the tech giant to track your browsing history. Here’s how to access and change your Google privacy settings.\n\nKaplan can also walk you through how to blur your home on Google maps.\n\nFinally, some sites allow you to log in using your Google or Facebook account, but Kaplan says don’t do it, because that just gives the companies even more information about you.\n\n“Education is the best ammunition you can have,” said Kaplan. “Once you’ve decided that you care about privacy and start educating yourself, you can achieve a pretty decent level for yourself.”'"""


URL_2 = 'https://www.protocol.com/vr-harassment-metaverse-bosworth'
HTML_2 = 'sample_webpages/sample_002.html'
TEXT_2 = """'How do you keep people safe in the metaverse? That\'s a question Meta, the company formerly known as Facebook, has been grappling with for some time. And the answer isn\'t all that simple.\n\nThe metaverse may be little more than a concept for now, but the safety problem is anything but theoretical: People regularly experience harassment in VR apps and experiences, including those running on Meta\'s Quest VR headset. Even the company\'s own employees are not immune. Earlier this year, an unnamed employee told co-workers in the company\'s internal Workplace forums that they had been accosted in Rec Room, with other players shouting the N-word at them without an obvious way to identify or stop the harasser. "Spoiler alert: I did not have a good time," the employee summarized.\n\nThe discussion, which became part of the public record when it was included in leaked Facebook documents supplied to Congress, shows that the problem is not isolated. One participant noted that similar cases are being brought up internally every few weeks, while another personally experienced harassment as well. "Multiple games have similar issues," one participant noted in the exchange.\n\nMeta\'s head of consumer hardware and incoming CTO, Andrew Bosworth, told Protocol on Friday that the specific incident discussed in the leaked document could have been mitigated if the employee had made use of existing reporting tools. "The tenor of the post [is] overstated and misinformed," Bosworth said. However, he also acknowledged that the problem of harassment in VR is real. He laid out ways the company is aiming to solve it, while pointing to trade-offs between making VR spaces safe and not policing people\'s private conversations. "We have [to strike] a pretty tough balance between privacy and integrity," Bosworth said.\n\nThis interview has been edited and condensed for clarity.\n\nAre your current reporting options enough to fight harassment in VR?\n\nI think the tools that we have in place are a good start. Blocking in virtual spaces is a very powerful tool, much more powerful than it is in asynchronous spaces. We can have someone not appear to exist to you. In addition, we can do reporting. This is a little bit similar to how you think of reporting in WhatsApp. Locally, on your device, totally private and secure, [you] have a little rolling buffer of what\'s the activity that happened. And you can say, "I want to report it," [and] send it to the platform developer or to us.\n\nThat kind of continuous recording is something you are only testing in Horizon so far, right?\n\nIt\'s a first-party tool that we built. It\'s the kind of thing that we encourage developers to adopt, or even make it easier for them to adopt over time. And we feel good about what that represents from a standpoint of a privacy integrity trade-off, because it\'s keeping the incidents private until somebody chooses of their own volition to say, "This is a situation that I want to raise visibility to."\n\nBut it\'s also just recording audio. How much does that have to do with the technical limitations of the Quest?\n\nIt\'s audio plus some metadata right now, [including which] users were in the area, for example. I don\'t think there is a technical limitation that prevents us from doing more. We\'re just trying to strike a trade-off between the privacy and the integrity challenges. That\'s going to be an area [where] we tread lightly, make sure [tools we roll out are] really well understood before we expand them.\n\nYou\'ve been saying that you want to put privacy first when building new products for Meta. How does that conflict with building safe products?\n\nSafety and privacy are highly related concepts and are both very high on our list of priorities. But, you know, even my friends say mean things to me sometimes. The path to infinite privacy is no product. The path to infinite safety is no social interaction. I don\'t think anyone\'s proposing we take these to their extremes.\n\nThe question is: What are healthy balances that give consumers control? And when you have privacy and safety trade-offs, that\'s super tough. The more [social VR spaces] are policed, the less privacy you\'re fundamentally able to ensure that people have. So it\'s case by case. There\'s not a one-size-fits-all solution on how to resolve those priorities when they compete.\n\nYou are also dealing with a space that\'s still very new, with a lot of VR games coming from relatively small companies. How can you help those developers fight harassment?\n\nWe want to build tools that developers can use, at the very least on our platforms. Identity is a strong example. If developers integrate our identity systems, even behind the scenes, they have a stronger ability to inherit things like blocks that suggest that two people don\'t want to be exposed to one another. There are tools that we can build — APIs, SDKs — that developers will be able to integrate. That\'s going to take time for us to build, but that\'s the direction we want to go in. Some of them we could potentially require for our own platform, some we would offer for those who choose to use [them].\n\nAs we move toward a metaverse world, what role will platform providers play in enforcing those rules? Right now, there seem to be two blueprints: game consoles, where companies have very strict safety requirements, and mobile platforms, where a company like Apple doesn\'t tell app developers how to do moderation. What will this look like for AR and VR devices in the future?\n\nOur vision for the metaverse is very interoperable. We very much expect a large number of the social spaces that people occupy in the metaverse to be cross-platform. To have people in them who are on mobile devices, in VR headsets, on PCs or laptops and on consoles and more. So this is kind of my point: You have to give a lot of the responsibility to the person hosting the social space. Are they informing customers of what the policies are and what the risks are? And if they\'re informed, are consumers allowed to make that decision for themselves?\n\nI don\'t want to be in a position where we\'re asserting control over what consumers are allowed to do in third-party applications, and what they\'re allowed to engage with.\n\nHow much does Meta\'s plan of getting a billion people to use the metaverse within the next decade depend on getting safety right from the get-go?\n\nI think it\'s hugely important. If the mainstream consumer puts a headset on for the first time and ends up having a really bad experience, that\'s obviously deleterious to our goals of growing the entire ecosystem. I don\'t think this is the kind of thing that can wait.\n\n\n\n'"""



URL_3 = 'https://www.computerworld.com/article/3644428/apple-should-enforce-the-app-store-privacy-promise.html',
HTML_3 = 'sample_webpages/sample_003.html'
TEXT_3 = """A Financial Times report seems to argue that Apple has allowed app developers to collect customer data from iPhone users without their permission. This isn’t a new story, but shows that those of us who have denied App Tracking permission may still be tracked, thanks to a loophole.\n\nWhen privacy…isn’t\n\nApple’s decision to introduce App Tracking Privacy controls generated lots of controversy and considerable pushback from Facebook. The latter even complained it would make life hard for small businesses. Apple took a little time, but introduced it all the same.\n\nHow the feature is meant to work is that when an app requests permission to track your activity across other companies’ apps and websites, you get to give permission. Most people say no, which means those entities that want to track you and what you do should find it much harder to do so.\n\nThe theory is that this denies companies that make their money collecting, curating, and selling your information the right to track what you do online. But it seems some developers have found what might be a loophole in the system – one that the Financial Times report suggests Apple is permitting developers to exploit.\n\nWhat\'s the loophole being used?\n\nThe report claims Facebook and Snapchat are exploiting a loophole in Apple’s guidelines in a way I feel undermines the spirit, if not the rules, around tracking.\n\nThe Apple Developer guidelines specific to fingerprinting and other technologies designed to identify a device or user say:\n\n“Per the Apple Developer Program License Agreement, you may not derive data from a device for the purpose of uniquely identifying it. Examples of user or device data include, but are not limited to: properties of a user’s web browser and its configuration, the user’s device and its configuration, the user’s location, or the user’s network connection. Apps that are found to be engaging in this practice, or that reference SDKs (including but not limited to Ad Networks, Attribution services and Analytics) that are, may be rejected from the App Store.”\n\nThe loophole is that services such as Snap and Facebook have changed the way they gather data to create anonymized groups of users, rather than to identify individuals.\n\nHow this works, apparently, is that they still collect your information, but do not share “unique and identifiable” data. Instead, they gather what they call “signals" from an iPhone at a group level, which enables them to target cohorts of users. Personal data is anonymized and unique identitifiers are not collected, apparently.\n\nFacebook’s Sheryl Sandberg says the company is also working to rebuild its ad infrastructure "using more aggregate or anonymized data."\n\nWhat this means in practice is that someone who regularly shops at Target online may be included (albeit anonymously) as part of a cohort of those who do so, but you shouldn’t have "Target shopper" beside your name on file.\n\nOne rule to ring them all\n\nThough it doesn’t work like that.\n\nThis MIT Technology Review report gives you a fairly terrifying insight into how even anonymized data can be exploited to build substantial quantities of information about you.\n\nWe know through bitter experience that surveillance capitalists will attempt to turn any amount of information into actionable data they can then sell to others. Those who purchase that data often then use AI and their existing data stacks to develop stacks of information about you. Which means that Target shopper will then receive ads personalized to them, even thought they’ve asked not to be tracked.\n\nThough no one — technically — broke the rules.\n\nI think this is a lull in an ongoing war. Apple always says it believes the best way to protect people’s data is not to gather it in the first place. It has made privacy a pillar to its product offering. We know the battle for privacy — like security — is an eternal one. Each time Apple improves it, others will seek to undermine it, as seems to be happening here.\n\nWhat’s missing is regulation.\n\nSmash their system\n\nI think the loophole used here contravenes the spirit and expectation of Apple’s rule, that this data “may not be combined with other data to track a user across apps and websites owned by other companies unless you have been granted permission to track by the user.”\n\nWhile Apple’s App Tracking controls do represent some privacy improvement for users, I do not believe an ordinary person in the street would understand the differences in nuance — they wouldn\'t easily be able to figure out why this loophole seems to be permitted.\n\nWith this in mind, Apple should intensify its privacy protections. I think it likely we will see it move to warn developers of future enforcement against such bending of its rules, probably at WWDC.\n\nApple’s prohibition cites its Developer Program License Agreement.\n\nThis strongly suggests it reserves the right to punish developers who go against the spirit of that deal. There should be consequences for companies that choose to undermine end user protection.\n\nShould Apple unfriend ... Facebook?\n\nIt wouldn’t be the first time Apple threatened to kick Facebook out. It last did so after it was found that domestic slaves were being sold on Facebook’s Instagram service.\n\nSo, will Apple boot Facebook from its servers for seemingly undermining the spirit of its developer agreement?\n\nNot if the Financial Times is to be believed — the report suggests Apple is turning a blind eye to this practice. It does also say that while Apple hasn’t responded to questions, it has said privacy “remains its North Star."\n\nMy feeling? It may be time for Apple to make a symbolic example to illustrate just how serious it is about privacy. That means punishing those who transgress the spirit of its developer agreement. It’s time to police the privacy promise of apps distributed via the App Store.\n\nPlease follow me on Twitter, or join me in the AppleHolic’s bar & grill and Apple Discussions groups on MeWe."""


URL_4 = 'https://www.wsj.com/articles/u-s-to-blacklist-more-chinese-tech-companies-over-surveillance-11639663210'
HTML_4 = 'sample_webpages/sample_004.html'
TEXT_4 = """The Biden administration added dozens of Chinese companies and research institutes to blacklists restricting access to U.S. investment and technology for their alleged support for China’s military and the mass surveillance of mainly Muslim ethnic groups.  The Commerce and Treasury departments targeted an array of Chinese businesses, from a company that lays undersea fiber-optic cables to developers of facial-recognition technology to the world’s largest commercial drone-maker, DJI Technology Co. The Commerce action also took aim at China’s Academy of Military Medical Sciences and a complex of research institutes under its control. Control of critical technologies is on the front lines of the global rivalry between Washington and Beijing.  All told, more than 40 Chinese companies and other entities were added to either the Commerce Department’s entity list, which restricts access to U.S. exports, or to a Treasury list banning American investment in companies supporting China’s military.  The agencies and White House officials said the targets were engaged in actions inimical to U.S. interests, including for assisting China’s surveillance and detention of Uyghurs and other Muslim ethnic groups in the Xinjiang region. “Today’s actions demonstrate the U.S. government’s vigilance against the PRC’s misuse of U.S. technology and investments that undermine U.S. national security,” Secretary of State Antony Blinken said, referring to the People’s Republic of China, the country’s official name. The Commerce Department said it was also restricting exports to some of the Chinese companies plus other entities operating in Georgia, Malaysia, and Turkey for diverting or attempting to divert U.S. items to Iran’s missile and other military programs. China’s Foreign Ministry has criticized the blacklisting of Chinese companies, with a spokesman in Beijing on Thursday accusing the U.S. of exerting “unwarranted suppression on Chinese companies.”  DJI declined to comment. Last year, when placed on the Commerce entity list, the company said, “DJI has done nothing to justify” the penalty. The Biden administration has accelerated its actions against Chinese technology companies in recent weeks, though officials have sometimes differed over how to proceed. In a Thursday meeting of multiple agencies, officials failed to agree on a Defense Department proposal to further restrict China’s largest semiconductor maker from access to U.S. chip-making technology, according to people briefed on the meeting. Semiconductor Manufacturing International Corp., known as SMIC, is already included on the Commerce entity list to restrict its access to U.S. tools to produce smaller, cutting-edge chips. But, the people said, the language in the listing isn’t broad enough to be effective.  Officials with the State and Energy departments, as well as the National Security Council, supported the Pentagon proposal to close the loophole while Commerce Department officials remained opposed, the people said. Instead, some officials proposed pursuing talks with allies to see if they would agree to block their own companies from selling additional technology to SMIC, the people said. Representatives from the Defense, State, Energy and Commerce departments didn’t immediately respond to requests for comment, and the National Security Council declined to comment. SMIC didn’t immediately respond to a request for comment. China’s activities in biotechnology have been a particular concern for the Biden administration, officials said. Thursday’s blacklisting of the Chinese academy and its research institutes was because of their support for the Chinese military, including research into “purported brain-control weaponry,” a Commerce Department statement said. The Treasury Department also pointed to biometric surveillance in its blacklisting of eight companies. “One of these companies developed customized software that supposedly recognizes specific ethnic minorities, including Tibetans and Uyghurs, and alerts authorities when it finds them,” Mr. Blinken said. “Another company produces software that includes a transcription and translation tool for the Uyghur language to enable authorities to scan residents’ devices for criminal content.” Also targeted Thursday was the successor company to undersea cable company Huawei Marine Networks, which was acquired from Huawei Technologies Co. by Hengtong Group, as well as other Hengtong subsidiaries. Hengtong didn’t immediately respond to a request for comment. The Biden administration has labeled China’s treatment of the Uyghurs as genocide and has previously taken action against Beijing, which denies any mistreatment. Earlier this month, the U.S. said it would stage a diplomatic boycott of the coming 2022 Winter Olympics in Beijing, meaning no officials would attend, though American athletes would still participate. Several other countries announced similar boycotts. Mr. Biden is expected to sign legislation to ban imports from Xinjiang over concerns about the use of forced labor. —Kate O’Keeffe contributed to this article. Write to Alex Leary at alex.leary@wsj.com and Ian Talley at ian.talley@wsj.com'"""
